{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "Download_df=pd.read_csv('C:/Users/sadik/OneDrive - Pace University/Desktop/Youtube Channel Analysis/Downloads/Download.csv',index_col=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "video_id          False\nchannelTitle      False\ntitle             False\ndescription        True\ntags               True\npublishedAt       False\nviewCount         False\nlikeCount         False\nfavouriteCount     True\ncommentCount       True\nduration          False\ndefinition        False\ncaption           False\ndtype: bool"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Download_df.isnull().any()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "video_id           object\nchannelTitle       object\ntitle              object\ndescription        object\ntags               object\npublishedAt        object\nviewCount           int64\nlikeCount           int64\nfavouriteCount    float64\ncommentCount      float64\nduration           object\ndefinition         object\ncaption              bool\ndtype: object"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "Download_df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Convert count columns to numeric\n",
    "numeric_cols = ['viewCount', 'likeCount', 'favouriteCount', 'commentCount']\n",
    "Download_df[numeric_cols] = Download_df[numeric_cols].apply(pd.to_numeric, errors = 'coerce', axis = 1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Publish day in the week\n",
    "Download_df['publishedAt']=Download_df['publishedAt'].astype(str)\n",
    "Download_df['publishedAt'] = Download_df['publishedAt'].apply(lambda x: parser.parse(x))\n",
    "Download_df['publishDayName'] = Download_df['publishedAt'].apply(lambda x: x.strftime(\"%A\"))#%%\n",
    "from googleapiclient.discovery import build\n",
    "from dateutil import parser\n",
    "import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# convert duration to seconds\n",
    "import isodate\n",
    "Download_df['durationSecs'] = Download_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "Download_df['durationSecs'] = Download_df['durationSecs'].astype('timedelta64[s]')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      durationSecs  duration\n0           2336.0  PT38M56S\n1           2601.0  PT43M21S\n2           1328.0   PT22M8S\n3           2258.0  PT37M38S\n4           1249.0  PT20M49S\n...            ...       ...\n2256         453.0   PT7M33S\n2257         350.0   PT5M50S\n2258         303.0    PT5M3S\n2259         345.0   PT5M45S\n2260         160.0   PT2M40S\n\n[2261 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>durationSecs</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2336.0</td>\n      <td>PT38M56S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2601.0</td>\n      <td>PT43M21S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1328.0</td>\n      <td>PT22M8S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2258.0</td>\n      <td>PT37M38S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1249.0</td>\n      <td>PT20M49S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2256</th>\n      <td>453.0</td>\n      <td>PT7M33S</td>\n    </tr>\n    <tr>\n      <th>2257</th>\n      <td>350.0</td>\n      <td>PT5M50S</td>\n    </tr>\n    <tr>\n      <th>2258</th>\n      <td>303.0</td>\n      <td>PT5M3S</td>\n    </tr>\n    <tr>\n      <th>2259</th>\n      <td>345.0</td>\n      <td>PT5M45S</td>\n    </tr>\n    <tr>\n      <th>2260</th>\n      <td>160.0</td>\n      <td>PT2M40S</td>\n    </tr>\n  </tbody>\n</table>\n<p>2261 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Download_df[['durationSecs', 'duration']]#%%\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Publish day in the week\n",
    "Download_df['publishedAt']=Download_df['publishedAt'].astype(str)\n",
    "Download_df['publishedAt'] = Download_df['publishedAt'].apply(lambda x: parser.parse(x))\n",
    "Download_df['publishDayName'] = Download_df['publishedAt'].apply(lambda x: x.strftime(\"%A\"))#%%\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# convert duration to seconds\n",
    "import isodate\n",
    "Download_df['durationSecs'] = Download_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "Download_df['durationSecs'] = Download_df['durationSecs'].astype('timedelta64[s]')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "         video_id      channelTitle  \\\n0     HZ8uXq5VG2w     Corey Schafer   \n1     vQQEaSnQ_bs     Corey Schafer   \n2     1KO_HZtHOWI     Corey Schafer   \n3     coZbOM6E47I     Corey Schafer   \n4     th5_9woFJmk     Corey Schafer   \n...           ...               ...   \n2256  4rfr6A3lO-Y  Alex The Analyst   \n2257  OTq2NRy_AGs  Alex The Analyst   \n2258  ya28cb3zFGE  Alex The Analyst   \n2259  Hsi2BG0SOiQ  Alex The Analyst   \n2260  6lQzbk6_OTw  Alex The Analyst   \n\n                                                  title  \\\n0     Python Tutorial: Simulate the Powerball Lotter...   \n1     Python YouTube API Tutorial: Using OAuth to Ac...   \n2     Python YouTube API Tutorial: Sort a Playlist b...   \n3     Python YouTube API Tutorial: Calculating the D...   \n4     Python YouTube API Tutorial: Getting Started -...   \n...                                                 ...   \n2256  Data Analyst Resume | Reviewing My Resume! | F...   \n2257  Working at a Big Company Vs Small Company | To...   \n2258      Data Analyst Salary | 100k with No Experience   \n2259  Truth About Big Companies | Told by a Fortune ...   \n2260                  Top 3 Data Analyst Skills in 2020   \n\n                                            description  \\\n0     In this Python Programming video, we will be l...   \n1     In this Python Programming Tutorial, we'll be ...   \n2     In this Python Programming Tutorial, we'll be ...   \n3     In this Python Programming Tutorial, we'll be ...   \n4     In this Python Programming Tutorial, we'll be ...   \n...                                                 ...   \n2256  Data Analyst Resume | Reviewing My Resume! | F...   \n2257  Working at a Big Company Vs Small Company | To...   \n2258  Data Analyst Salary | 100k with No Experience ...   \n2259  Truth About Big Companies // There are a ton o...   \n2260  Top 3 Data Analyst Skills in 2020 // There are...   \n\n                                                   tags  \\\n0     ['python', 'lottery', 'powerball', 'simulation...   \n1     ['python', 'youtube api', 'youtube-api', 'yout...   \n2     ['python', 'youtube api', 'youtube-api', 'yout...   \n3     ['python', 'youtube api', 'youtube-api', 'pyth...   \n4     ['python', 'youtube api', 'youtube-api', 'pyth...   \n...                                                 ...   \n2256  ['Data Analyst', 'How to become a data analyst...   \n2257  ['Data Analyst', 'How to become a Data Analyst...   \n2258  ['Data Analyst Salary', 'Data analyst with no ...   \n2259  ['Working at a big company', 'Big company data...   \n2260  ['Top skills for data analyst', 'Top 3 skills ...   \n\n                   publishedAt  viewCount  likeCount  favouriteCount  \\\n0    2023-01-09 18:45:00+00:00    97171.0     3556.0             NaN   \n1    2020-09-10 14:15:03+00:00   126318.0     2499.0             NaN   \n2    2020-07-31 14:30:00+00:00    42126.0     1068.0             NaN   \n3    2020-06-10 15:53:26+00:00    50394.0     1509.0             NaN   \n4    2020-05-29 16:17:07+00:00   174028.0     5199.0             NaN   \n...                        ...        ...        ...             ...   \n2256 2020-01-30 14:07:55+00:00    60275.0     1476.0             NaN   \n2257 2020-01-25 16:38:39+00:00    13253.0      366.0             NaN   \n2258 2020-01-23 03:16:09+00:00    56732.0     2004.0             NaN   \n2259 2020-01-21 03:52:15+00:00     7048.0      269.0             NaN   \n2260 2020-01-17 14:31:39+00:00    25781.0     1282.0             NaN   \n\n      commentCount  duration definition  caption publishDayName  durationSecs  \n0            768.0  PT38M56S         hd    False         Monday        2336.0  \n1            353.0  PT43M21S         hd    False       Thursday        2601.0  \n2            128.0   PT22M8S         hd    False         Friday        1328.0  \n3            179.0  PT37M38S         hd    False      Wednesday        2258.0  \n4            324.0  PT20M49S         hd    False         Friday        1249.0  \n...            ...       ...        ...      ...            ...           ...  \n2256          64.0   PT7M33S         hd    False       Thursday         453.0  \n2257          21.0   PT5M50S         hd    False       Saturday         350.0  \n2258         224.0    PT5M3S         hd    False       Thursday         303.0  \n2259          17.0   PT5M45S         hd    False        Tuesday         345.0  \n2260         137.0   PT2M40S         hd    False         Friday         160.0  \n\n[2261 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_id</th>\n      <th>channelTitle</th>\n      <th>title</th>\n      <th>description</th>\n      <th>tags</th>\n      <th>publishedAt</th>\n      <th>viewCount</th>\n      <th>likeCount</th>\n      <th>favouriteCount</th>\n      <th>commentCount</th>\n      <th>duration</th>\n      <th>definition</th>\n      <th>caption</th>\n      <th>publishDayName</th>\n      <th>durationSecs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HZ8uXq5VG2w</td>\n      <td>Corey Schafer</td>\n      <td>Python Tutorial: Simulate the Powerball Lotter...</td>\n      <td>In this Python Programming video, we will be l...</td>\n      <td>['python', 'lottery', 'powerball', 'simulation...</td>\n      <td>2023-01-09 18:45:00+00:00</td>\n      <td>97171.0</td>\n      <td>3556.0</td>\n      <td>NaN</td>\n      <td>768.0</td>\n      <td>PT38M56S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Monday</td>\n      <td>2336.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vQQEaSnQ_bs</td>\n      <td>Corey Schafer</td>\n      <td>Python YouTube API Tutorial: Using OAuth to Ac...</td>\n      <td>In this Python Programming Tutorial, we'll be ...</td>\n      <td>['python', 'youtube api', 'youtube-api', 'yout...</td>\n      <td>2020-09-10 14:15:03+00:00</td>\n      <td>126318.0</td>\n      <td>2499.0</td>\n      <td>NaN</td>\n      <td>353.0</td>\n      <td>PT43M21S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Thursday</td>\n      <td>2601.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1KO_HZtHOWI</td>\n      <td>Corey Schafer</td>\n      <td>Python YouTube API Tutorial: Sort a Playlist b...</td>\n      <td>In this Python Programming Tutorial, we'll be ...</td>\n      <td>['python', 'youtube api', 'youtube-api', 'yout...</td>\n      <td>2020-07-31 14:30:00+00:00</td>\n      <td>42126.0</td>\n      <td>1068.0</td>\n      <td>NaN</td>\n      <td>128.0</td>\n      <td>PT22M8S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Friday</td>\n      <td>1328.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>coZbOM6E47I</td>\n      <td>Corey Schafer</td>\n      <td>Python YouTube API Tutorial: Calculating the D...</td>\n      <td>In this Python Programming Tutorial, we'll be ...</td>\n      <td>['python', 'youtube api', 'youtube-api', 'pyth...</td>\n      <td>2020-06-10 15:53:26+00:00</td>\n      <td>50394.0</td>\n      <td>1509.0</td>\n      <td>NaN</td>\n      <td>179.0</td>\n      <td>PT37M38S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Wednesday</td>\n      <td>2258.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>th5_9woFJmk</td>\n      <td>Corey Schafer</td>\n      <td>Python YouTube API Tutorial: Getting Started -...</td>\n      <td>In this Python Programming Tutorial, we'll be ...</td>\n      <td>['python', 'youtube api', 'youtube-api', 'pyth...</td>\n      <td>2020-05-29 16:17:07+00:00</td>\n      <td>174028.0</td>\n      <td>5199.0</td>\n      <td>NaN</td>\n      <td>324.0</td>\n      <td>PT20M49S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Friday</td>\n      <td>1249.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2256</th>\n      <td>4rfr6A3lO-Y</td>\n      <td>Alex The Analyst</td>\n      <td>Data Analyst Resume | Reviewing My Resume! | F...</td>\n      <td>Data Analyst Resume | Reviewing My Resume! | F...</td>\n      <td>['Data Analyst', 'How to become a data analyst...</td>\n      <td>2020-01-30 14:07:55+00:00</td>\n      <td>60275.0</td>\n      <td>1476.0</td>\n      <td>NaN</td>\n      <td>64.0</td>\n      <td>PT7M33S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Thursday</td>\n      <td>453.0</td>\n    </tr>\n    <tr>\n      <th>2257</th>\n      <td>OTq2NRy_AGs</td>\n      <td>Alex The Analyst</td>\n      <td>Working at a Big Company Vs Small Company | To...</td>\n      <td>Working at a Big Company Vs Small Company | To...</td>\n      <td>['Data Analyst', 'How to become a Data Analyst...</td>\n      <td>2020-01-25 16:38:39+00:00</td>\n      <td>13253.0</td>\n      <td>366.0</td>\n      <td>NaN</td>\n      <td>21.0</td>\n      <td>PT5M50S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Saturday</td>\n      <td>350.0</td>\n    </tr>\n    <tr>\n      <th>2258</th>\n      <td>ya28cb3zFGE</td>\n      <td>Alex The Analyst</td>\n      <td>Data Analyst Salary | 100k with No Experience</td>\n      <td>Data Analyst Salary | 100k with No Experience ...</td>\n      <td>['Data Analyst Salary', 'Data analyst with no ...</td>\n      <td>2020-01-23 03:16:09+00:00</td>\n      <td>56732.0</td>\n      <td>2004.0</td>\n      <td>NaN</td>\n      <td>224.0</td>\n      <td>PT5M3S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Thursday</td>\n      <td>303.0</td>\n    </tr>\n    <tr>\n      <th>2259</th>\n      <td>Hsi2BG0SOiQ</td>\n      <td>Alex The Analyst</td>\n      <td>Truth About Big Companies | Told by a Fortune ...</td>\n      <td>Truth About Big Companies // There are a ton o...</td>\n      <td>['Working at a big company', 'Big company data...</td>\n      <td>2020-01-21 03:52:15+00:00</td>\n      <td>7048.0</td>\n      <td>269.0</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>PT5M45S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Tuesday</td>\n      <td>345.0</td>\n    </tr>\n    <tr>\n      <th>2260</th>\n      <td>6lQzbk6_OTw</td>\n      <td>Alex The Analyst</td>\n      <td>Top 3 Data Analyst Skills in 2020</td>\n      <td>Top 3 Data Analyst Skills in 2020 // There are...</td>\n      <td>['Top skills for data analyst', 'Top 3 skills ...</td>\n      <td>2020-01-17 14:31:39+00:00</td>\n      <td>25781.0</td>\n      <td>1282.0</td>\n      <td>NaN</td>\n      <td>137.0</td>\n      <td>PT2M40S</td>\n      <td>hd</td>\n      <td>False</td>\n      <td>Friday</td>\n      <td>160.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2261 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Download_df[['durationSecs', 'duration']]\n",
    "Download_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "Download_df['tags']=Download_df['tags'].astype(str)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Add tag count\n",
    "Download_df['tagCount'] = Download_df['tags'].apply(lambda x: 0 if x is None else len(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Comments and likes per 1000 view ratio\n",
    "Download_df['likeRatio'] = Download_df['likeCount']/ Download_df['viewCount'] * 1000\n",
    "Download_df['commentRatio'] = Download_df['commentCount']/ Download_df['viewCount'] * 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Title character length\n",
    "Download_df['titleLength'] = Download_df['title'].apply(lambda x: len(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "Download_df.to_csv('C:/Users/sadik/OneDrive - Pace University/Desktop/Youtube Channel Analysis/Downloads/Final.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
